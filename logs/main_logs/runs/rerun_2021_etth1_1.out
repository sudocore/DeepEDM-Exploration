Setting seed to 2021
{'activation_fn': 'selu',
 'add_pe': True,
 'augmentation_ratio': 0,
 'batch_size': 32,
 'checkpoints': './checkpoints',
 'clip_grad_norm': 1.0,
 'condor_job': True,
 'data': 'ETTh1',
 'data_path': 'ETTh1.csv',
 'delay': 9,
 'des': 'test',
 'devices': '0,1',
 'dist_projection_dim': -1,
 'edm_dropout': 0.1,
 'embed': 'timeF',
 'features': 'M',
 'freq': 'h',
 'gpu': 0,
 'inverse': False,
 'is_training': 1,
 'itr': 1,
 'label_len': 48,
 'latent_channel_dim': -1,
 'learning_rate': 0.0005,
 'loss': 'mae_tdt',
 'loss_type': 'mae',
 'lradj': 'custom',
 'min_lr': 5e-05,
 'mlp_dropout': 0.1,
 'model': 'DeepEDM',
 'model_config': {'edm_params': {'activation_fn': 'selu',
                                 'add_pe': True,
                                 'delay': 9,
                                 'dist_projection_dim': 64,
                                 'dropout': 0.1,
                                 'layer_norm': True,
                                 'method': 'simplex',
                                 'n_proj_layers': 1,
                                 'theta': 1.0,
                                 'time_delay_stride': 2},
                  'encoder_params': {'activation_fn': 'selu',
                                     'add_pe': True,
                                     'dropout': 0.1,
                                     'in_channels': 7,
                                     'latent_channel_dim': 7,
                                     'mlp_layers': 3,
                                     'use_encoder': False},
                  'lookback_len': 192,
                  'n_edm_blocks': 2,
                  'out_pred_len': 96,
                  'type': 'EDM'},
 'model_id': 'ETTh1_rerun_2021',
 'n_edm_blocks': 2,
 'n_mlp_layers': 3,
 'n_proj_layers': -1,
 'num_workers': 4,
 'opt': {'clip_grad_norm': 1.0,
         'early_stopping_patience': 30,
         'epochs': 100,
         'learning_rate': 0.0005,
         'min_lr': 5e-05,
         'reduce_lr_factor': 0.9,
         'schedule_type': 'custom',
         'type': 'AdamW',
         'weight_decay': 1e-05},
 'output_dir': '.',
 'patience': 10,
 'pred_len': 96,
 'reduce_lr_factor': 0.9,
 'root_path': './dataset/ETT-small/',
 'seasonal_patterns': 'Monthly',
 'seed': 2021,
 'seq_len': 192,
 'target': 'OT',
 'task_name': 'long_term_forecast',
 'tdt_loss': True,
 'theta': -1,
 'time_delay_stride': 2,
 'train_epochs': 150,
 'use_amp': False,
 'use_dtw': False,
 'use_gpu': True,
 'use_multi_gpu': True}
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTh1_rerun_2021    Model:              DeepEDM             

[1mData Loader[0m
  Data:               ETTh1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints       

[1mForecasting Task[0m
  Seq Len:            192                 Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m

[1mRun Parameters[0m
  Num Workers:        4                   Itr:                1                   
  Train Epochs:       150                 Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.0005              
  Des:                test                Loss:               mae_tdt             
  Lradj:              custom              Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      1                   Devices:            0,1                 

{'clip_grad_norm': 1.0,
 'early_stopping_patience': 30,
 'epochs': 100,
 'learning_rate': 0.0005,
 'min_lr': 5e-05,
 'reduce_lr_factor': 0.9,
 'schedule_type': 'custom',
 'type': 'AdamW',
 'weight_decay': 1e-05}

{'edm_params': {'activation_fn': 'selu',
                'add_pe': True,
                'delay': 9,
                'dist_projection_dim': 64,
                'dropout': 0.1,
                'layer_norm': True,
                'method': 'simplex',
                'n_proj_layers': 1,
                'theta': 1.0,
                'time_delay_stride': 2},
 'encoder_params': {'activation_fn': 'selu',
                    'add_pe': True,
                    'dropout': 0.1,
                    'in_channels': 7,
                    'latent_channel_dim': 7,
                    'mlp_layers': 3,
                    'use_encoder': False},
 'lookback_len': 192,
 'n_edm_blocks': 2,
 'out_pred_len': 96,
 'type': 'EDM'}

model: Model(
  (encoder): InputEncoder(
    (mlp_projection): Sequential(
      (0): Linear(in_features=192, out_features=96, bias=True)
      (1): Dropout(p=0.1, inplace=False)
      (2): SELU()
      (3): Linear(in_features=96, out_features=96, bias=True)
      (4): Dropout(p=0.1, inplace=False)
      (5): SELU()
      (6): Linear(in_features=96, out_features=96, bias=True)
    )
  )
  (edm_blocks): ModuleList(
    (0-1): 2 x EDM(
      (activation_fn): SELU()
      (projection): Sequential(
        (0): Linear(in_features=9, out_features=64, bias=True)
      )
      (pe): LearnablePositionalEmbedding()
      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (attn_dropout): Dropout(p=0.1, inplace=False)
      (undelay): Sequential(
        (0): Linear(in_features=414, out_features=96, bias=True)
        (1): Dropout(p=0.1, inplace=False)
        (2): SELU()
        (3): Linear(in_features=96, out_features=96, bias=True)
      )
    )
  )
  (gate_edm): Linear(in_features=96, out_features=1, bias=True)
)
>>>>>>>start training : long_term_forecast_ETTh1_rerun_2021_DeepEDM_ETTh1_ftM_sl192_ll48_pl96_emdtimeF_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8353
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.3051197
	speed: 0.0776s/iter; left time: 3030.3457s
	iters: 200, epoch: 1 | loss: 0.3089384
	speed: 0.0481s/iter; left time: 1871.8056s
Epoch: 1 cost time: 15.37576174736023
Vali Metrics: mse:0.6983, mae:0.5495
Test Metrics: mse:0.3781217, mae:0.3917093
Epoch: 1, Steps: 261 | Train Loss: 0.3254979 Vali Loss: 0.6239179 Test Loss: 0.3849155
Validation loss decreased (inf --> 0.623918).  Saving model ...
Reducing learning rate to 0.000450
	iters: 100, epoch: 2 | loss: 0.3031225
	speed: 0.1532s/iter; left time: 5941.9031s
	iters: 200, epoch: 2 | loss: 0.3032952
	speed: 0.0483s/iter; left time: 1870.5804s
Epoch: 2 cost time: 12.021021366119385
Vali Metrics: mse:0.6888, mae:0.5446
Test Metrics: mse:0.3704309, mae:0.3859842
Epoch: 2, Steps: 261 | Train Loss: 0.2905256 Vali Loss: 0.6167285 Test Loss: 0.3782076
Validation loss decreased (0.623918 --> 0.616729).  Saving model ...
Reducing learning rate to 0.000405
	iters: 100, epoch: 3 | loss: 0.2969968
	speed: 0.1394s/iter; left time: 5370.9078s
	iters: 200, epoch: 3 | loss: 0.2549690
	speed: 0.0488s/iter; left time: 1876.6212s
Epoch: 3 cost time: 12.389533996582031
Vali Metrics: mse:0.6713, mae:0.5352
Test Metrics: mse:0.366108, mae:0.3841389
Epoch: 3, Steps: 261 | Train Loss: 0.2828887 Vali Loss: 0.6032486 Test Loss: 0.3751235
Validation loss decreased (0.616729 --> 0.603249).  Saving model ...
Reducing learning rate to 0.000365
	iters: 100, epoch: 4 | loss: 0.2631539
	speed: 0.1386s/iter; left time: 5303.3717s
	iters: 200, epoch: 4 | loss: 0.2819750
	speed: 0.0419s/iter; left time: 1598.5164s
Epoch: 4 cost time: 11.745259046554565
Vali Metrics: mse:0.6720, mae:0.5377
Test Metrics: mse:0.3626642, mae:0.3829685
Epoch: 4, Steps: 261 | Train Loss: 0.2786108 Vali Loss: 0.6048426 Test Loss: 0.3728163
EarlyStopping counter: 1 out of 10
Reducing learning rate to 0.000328
	iters: 100, epoch: 5 | loss: 0.2789392
	speed: 0.1307s/iter; left time: 4968.5928s
	iters: 200, epoch: 5 | loss: 0.2846829
	speed: 0.0486s/iter; left time: 1841.2150s
Epoch: 5 cost time: 12.599544286727905
Vali Metrics: mse:0.6772, mae:0.5403
Test Metrics: mse:0.3617274, mae:0.3825197
Epoch: 5, Steps: 261 | Train Loss: 0.2761144 Vali Loss: 0.6087440 Test Loss: 0.3721235
EarlyStopping counter: 2 out of 10
Reducing learning rate to 0.000295
	iters: 100, epoch: 6 | loss: 0.2630574
	speed: 0.1486s/iter; left time: 5607.6917s
	iters: 200, epoch: 6 | loss: 0.2711567
	speed: 0.0491s/iter; left time: 1849.7787s
Epoch: 6 cost time: 12.697917222976685
Vali Metrics: mse:0.6862, mae:0.5454
Test Metrics: mse:0.3601567, mae:0.3821691
Epoch: 6, Steps: 261 | Train Loss: 0.2740972 Vali Loss: 0.6157928 Test Loss: 0.3711629
EarlyStopping counter: 3 out of 10
Reducing learning rate to 0.000266
	iters: 100, epoch: 7 | loss: 0.2731439
	speed: 0.1569s/iter; left time: 5881.6454s
	iters: 200, epoch: 7 | loss: 0.2648734
	speed: 0.0500s/iter; left time: 1867.8247s
Epoch: 7 cost time: 12.943894624710083
Vali Metrics: mse:0.6741, mae:0.5408
Test Metrics: mse:0.3640708, mae:0.3830613
Epoch: 7, Steps: 261 | Train Loss: 0.2725873 Vali Loss: 0.6074873 Test Loss: 0.3735660
EarlyStopping counter: 4 out of 10
Reducing learning rate to 0.000239
	iters: 100, epoch: 8 | loss: 0.2659692
	speed: 0.1522s/iter; left time: 5666.7498s
	iters: 200, epoch: 8 | loss: 0.2790081
	speed: 0.0447s/iter; left time: 1657.8703s
Epoch: 8 cost time: 12.22394847869873
Vali Metrics: mse:0.6676, mae:0.5370
Test Metrics: mse:0.3590193, mae:0.3826318
Epoch: 8, Steps: 261 | Train Loss: 0.2716504 Vali Loss: 0.6023082 Test Loss: 0.3708256
Validation loss decreased (0.603249 --> 0.602308).  Saving model ...
Reducing learning rate to 0.000215
	iters: 100, epoch: 9 | loss: 0.2851982
	speed: 0.1591s/iter; left time: 5881.7727s
	iters: 200, epoch: 9 | loss: 0.2755288
	speed: 0.0489s/iter; left time: 1801.0072s
Epoch: 9 cost time: 13.119871854782104
Vali Metrics: mse:0.6687, mae:0.5387
Test Metrics: mse:0.3623724, mae:0.3827740
Epoch: 9, Steps: 261 | Train Loss: 0.2707093 Vali Loss: 0.6036747 Test Loss: 0.3725732
EarlyStopping counter: 1 out of 10
Reducing learning rate to 0.000194
	iters: 100, epoch: 10 | loss: 0.2726731
	speed: 0.1500s/iter; left time: 5505.3607s
	iters: 200, epoch: 10 | loss: 0.2675112
	speed: 0.0512s/iter; left time: 1875.4425s
Epoch: 10 cost time: 13.530759334564209
Vali Metrics: mse:0.6714, mae:0.5384
Test Metrics: mse:0.363319, mae:0.3827598
Epoch: 10, Steps: 261 | Train Loss: 0.2698486 Vali Loss: 0.6049154 Test Loss: 0.3730394
EarlyStopping counter: 2 out of 10
Reducing learning rate to 0.000174
	iters: 100, epoch: 11 | loss: 0.2542983
	speed: 0.1481s/iter; left time: 5397.8663s
	iters: 200, epoch: 11 | loss: 0.2793203
	speed: 0.0394s/iter; left time: 1432.7629s
Epoch: 11 cost time: 10.92855191230774
Vali Metrics: mse:0.6814, mae:0.5427
Test Metrics: mse:0.3598426, mae:0.3825303
Epoch: 11, Steps: 261 | Train Loss: 0.2692128 Vali Loss: 0.6120303 Test Loss: 0.3711864
EarlyStopping counter: 3 out of 10
Reducing learning rate to 0.000157
	iters: 100, epoch: 12 | loss: 0.2703118
	speed: 0.1227s/iter; left time: 4437.6435s
	iters: 200, epoch: 12 | loss: 0.2602398
	speed: 0.0353s/iter; left time: 1272.9473s
Epoch: 12 cost time: 9.650576829910278
Vali Metrics: mse:0.6898, mae:0.5468
Test Metrics: mse:0.3643858, mae:0.3840727
Epoch: 12, Steps: 261 | Train Loss: 0.2686496 Vali Loss: 0.6182983 Test Loss: 0.3742292
EarlyStopping counter: 4 out of 10
Reducing learning rate to 0.000141
	iters: 100, epoch: 13 | loss: 0.2633002
	speed: 0.1293s/iter; left time: 4643.4354s
	iters: 200, epoch: 13 | loss: 0.2588308
	speed: 0.0400s/iter; left time: 1431.8869s
Epoch: 13 cost time: 10.820345878601074
Vali Metrics: mse:0.6774, mae:0.5415
Test Metrics: mse:0.3605343, mae:0.3834743
Epoch: 13, Steps: 261 | Train Loss: 0.2681503 Vali Loss: 0.6094542 Test Loss: 0.3720043
EarlyStopping counter: 5 out of 10
Reducing learning rate to 0.000127
	iters: 100, epoch: 14 | loss: 0.2706612
	speed: 0.1230s/iter; left time: 4386.6652s
	iters: 200, epoch: 14 | loss: 0.2562392
	speed: 0.0391s/iter; left time: 1390.9010s
Epoch: 14 cost time: 10.11577320098877
Vali Metrics: mse:0.6734, mae:0.5393
Test Metrics: mse:0.3595806, mae:0.3833037
Epoch: 14, Steps: 261 | Train Loss: 0.2677933 Vali Loss: 0.6063191 Test Loss: 0.3714421
EarlyStopping counter: 6 out of 10
Reducing learning rate to 0.000114
	iters: 100, epoch: 15 | loss: 0.2615142
	speed: 0.1304s/iter; left time: 4616.1199s
	iters: 200, epoch: 15 | loss: 0.2590631
	speed: 0.0427s/iter; left time: 1506.6611s
Epoch: 15 cost time: 11.42716360092163
Vali Metrics: mse:0.6792, mae:0.5428
Test Metrics: mse:0.3605872, mae:0.3840988
Epoch: 15, Steps: 261 | Train Loss: 0.2673954 Vali Loss: 0.6109871 Test Loss: 0.3723430
EarlyStopping counter: 7 out of 10
Reducing learning rate to 0.000103
	iters: 100, epoch: 16 | loss: 0.2683805
	speed: 0.1277s/iter; left time: 4486.3654s
	iters: 200, epoch: 16 | loss: 0.2646979
	speed: 0.0441s/iter; left time: 1544.7921s
Epoch: 16 cost time: 11.633342027664185
Vali Metrics: mse:0.6797, mae:0.5426
Test Metrics: mse:0.3623921, mae:0.3837806
Epoch: 16, Steps: 261 | Train Loss: 0.2669572 Vali Loss: 0.6111432 Test Loss: 0.3730863
EarlyStopping counter: 8 out of 10
Reducing learning rate to 0.000093
	iters: 100, epoch: 17 | loss: 0.2749968
	speed: 0.1385s/iter; left time: 4830.2934s
	iters: 200, epoch: 17 | loss: 0.2952139
	speed: 0.0433s/iter; left time: 1505.4751s
Epoch: 17 cost time: 11.655178546905518
Vali Metrics: mse:0.6809, mae:0.5428
Test Metrics: mse:0.3634942, mae:0.3844067
Epoch: 17, Steps: 261 | Train Loss: 0.2666815 Vali Loss: 0.6118346 Test Loss: 0.3739504
EarlyStopping counter: 9 out of 10
Reducing learning rate to 0.000083
	iters: 100, epoch: 18 | loss: 0.2955120
	speed: 0.1448s/iter; left time: 5011.9790s
	iters: 200, epoch: 18 | loss: 0.2862927
	speed: 0.0454s/iter; left time: 1566.1687s
Epoch: 18 cost time: 12.22659707069397
Vali Metrics: mse:0.6816, mae:0.5434
Test Metrics: mse:0.3597349, mae:0.3832657
Epoch: 18, Steps: 261 | Train Loss: 0.2664046 Vali Loss: 0.6124946 Test Loss: 0.3715003
EarlyStopping counter: 10 out of 10
Early stopping
loading model, best model path: ./checkpoints/long_term_forecast_ETTh1_rerun_2021_DeepEDM_ETTh1_ftM_sl192_ll48_pl96_emdtimeF_test_0/checkpoint.pth
>>>>>>>testing : long_term_forecast_ETTh1_rerun_2021_DeepEDM_ETTh1_ftM_sl192_ll48_pl96_emdtimeF_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (2785, 96, 7) (2785, 96, 7)
mse:0.3589349091053009, mae:0.382638156414032, dtw:not calculated
